# Web Scraping Projects 🕷️

## 📌 Description  
A collection of 18+ web scraping and automation projects. The scripts were built for various tasks, including data extraction, processing, and automation of web activities.

Most projects include:  
- Data parsing from websites via **requests** and **BeautifulSoup**  
- Browser automation and dynamic content handling via **Selenium**  
- Structured data storage in **SQLite3** databases  
- Some projects used **Django** for admin panels and ORM functionality

This repo contains examples of my practical experience working with different scraping scenarios, including handling large datasets (hundreds of thousands of records).

---

## 🛠️ Tech Stack  
- **Python**  
- **Requests**  
- **BeautifulSoup4**  
- **Selenium**  
- **SQLite3**  
- **Django** (for ORM and admin panel in some projects)

---

## 🗂️ Repository Structure  
```
project01/
├── root_project01/
│   ├── django_project01/
│   └── modules/         # scraping scripts

project02/
├── root_project02/
│   ├── django_project02/
│   └── modules/

...

project18/
├── root_project18/
│   ├── django_project18/
│   └── modules/
```

---

## 🚀 How to Run  
Each project has its own structure, but in general:  

1. Navigate to the project folder:  
```
cd project01/root_project01/modules/
```

2. Install dependencies (if not already):  
```
pip install -r requirements.txt
```

3. Run the script:  
```
python script_name.py
```

For Django-based projects, navigate to the `django_project` folder and run the Django server:  
```
python manage.py runserver
```

---

## ⚠️ Notes  
- This repo contains simplified versions of real commercial scraping tools and bots developed during freelance work.  
- Sensitive data, credentials, and proprietary code have been removed.  
- Projects are for demonstration purposes only.

---

## 📫 Contact  
For questions or collaboration:  
📧 fritch.high@gmail.com
